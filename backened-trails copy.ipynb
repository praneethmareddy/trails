{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74eeabdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample files created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directories\n",
    "folders = ['ciq_files', 'templates', 'logs']\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Create CIQ Excel files\n",
    "df_airtel = pd.DataFrame({\n",
    "    'Parameter': ['x1', 'x2', 'x3'],\n",
    "    'Value': [10, 20, 30]\n",
    "})\n",
    "df_jio = pd.DataFrame({\n",
    "    'Parameter': ['y1', 'y2', 'y3'],\n",
    "    'Value': [40, 50, 60]\n",
    "})\n",
    "\n",
    "df_airtel.to_excel('ciq_files/airtel_config.xlsx', index=False)\n",
    "df_jio.to_excel('ciq_files/jio_config.xlsx', index=False)\n",
    "\n",
    "# Create Template files\n",
    "with open('templates/airtel_template.txt', 'w') as f:\n",
    "    f.write(\"@BaseStationA\\nparam1, param2\\n100, 200\\n\")\n",
    "with open('templates/jio_template.txt', 'w') as f:\n",
    "    f.write(\"@BaseStationB\\nparamA, paramB\\n300, 400\\n\")\n",
    "\n",
    "# Create Log files\n",
    "with open('logs/airtel_log.txt', 'w') as f:\n",
    "    f.write(\"2025-05-11 12:00:00 [INFO] Base station configured successfully with parameters x1=10, x2=20.\\n\")\n",
    "with open('logs/jio_log.txt', 'w') as f:\n",
    "    f.write(\"2025-05-11 12:05:00 [INFO] Base station configured with parameters y1=40, y2=50.\\n\")\n",
    "\n",
    "print(\"Sample files created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b15b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709caab518aa4670b0c84b33a69a29a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saip9\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\saip9\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd83ea5b746e47fa9554cae700a3db25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f2b76363aa4191948eae904f4c8c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b2fa1d69574f41870ce955ea83ff28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a152837c1a14380a6fb5a5a6cebce47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saip9\\AppData\\Local\\Temp\\ipykernel_17768\\956159988.py:26: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3.1:8b\")\n"
     ]
    }
   ],
   "source": [
    "# pip install pandas openpyxl sentence-transformers transformers langchain-community langchain-core\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# ðŸ“ Paths\n",
    "CIQ_FOLDER = './ciq_files'\n",
    "TEMPLATES_FOLDER = './templates'\n",
    "LOGS_FOLDER = './logs'\n",
    "\n",
    "# ðŸ”§ Models\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model_name = \"gpt2\"  # or use 'distilbert-base-uncased', 'bert-base-uncased', etc.\n",
    "\n",
    "# Load the tokenizer and model directly (no authentication needed)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1:8b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc5a27bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl (15.0 MB)\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/15.0 MB 2.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.3/15.0 MB 2.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.6/15.0 MB 2.3 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.4/15.0 MB 2.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.9/15.0 MB 2.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.7/15.0 MB 2.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.2/15.0 MB 2.6 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.7/15.0 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 5.2/15.0 MB 2.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 6.3/15.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 7.3/15.0 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 8.4/15.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 9.4/15.0 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.5/15.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.5/15.0 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.3/15.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.4/15.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.2/15.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.0/15.0 MB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84ac7e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ciq docs from: ciq_files\n",
      "  Reading: ciq_files\\airtel_config.xlsx\n",
      "  Reading: ciq_files\\jio_config.xlsx\n",
      "Loaded 2 ciq docs\n",
      "\n",
      "Loading template docs from: templates\n",
      "  Reading: templates\\airtel_template.txt\n",
      "  Reading: templates\\jio_template.txt\n",
      "Loaded 2 template docs\n",
      "\n",
      "Loading log docs from: logs\n",
      "  Reading: logs\\airtel_log.txt\n",
      "  Reading: logs\\jio_log.txt\n",
      "Loaded 2 log docs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# === Settings ===\n",
    "CIQ_FOLDER = \"ciq_files\"\n",
    "TEMPLATES_FOLDER = \"templates\"\n",
    "LOGS_FOLDER = \"logs\"\n",
    "\n",
    "# === Embedding model ===\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# === Helper: Load and wrap docs ===\n",
    "def load_docs(folder, doc_type):\n",
    "    docs = []\n",
    "    print(f\"Loading {doc_type} docs from: {folder}\")\n",
    "    for file in glob.glob(f\"{folder}/*\"):\n",
    "        print(f\"  Reading: {file}\")\n",
    "        try:\n",
    "            if file.endswith(\".xlsx\") and doc_type == \"ciq\":\n",
    "                df = pd.read_excel(file, sheet_name=None)\n",
    "                text = \"\\n\".join(\n",
    "                    f\"Sheet: {sheet}\\n{df[sheet].head(5).to_csv(index=False)}\"\n",
    "                    for sheet in df\n",
    "                )\n",
    "            else:\n",
    "                with open(file, \"r\") as f:\n",
    "                    text = f.read()\n",
    "            docs.append(Document(page_content=text, metadata={\"type\": doc_type, \"path\": file}))\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Failed to read {file}: {e}\")\n",
    "    print(f\"Loaded {len(docs)} {doc_type} docs\\n\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "# === Load documents ===\n",
    "ciq_docs = load_docs(CIQ_FOLDER, \"ciq\")\n",
    "template_docs = load_docs(TEMPLATES_FOLDER, \"template\")\n",
    "log_docs = load_docs(LOGS_FOLDER, \"log\")\n",
    "\n",
    "# === Store each in separate FAISS DB ===\n",
    "db_ciq = FAISS.from_documents(ciq_docs, embedder)\n",
    "db_template = FAISS.from_documents(template_docs, embedder)\n",
    "db_log = FAISS.from_documents(log_docs, embedder)\n",
    "\n",
    "# === Routing Agent ===\n",
    "router_llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "def route_db(query):\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "Given the query below, classify it into one of the following categories:\n",
    "- ciq: Related to Excel/CIQ network config\n",
    "- template: Related to network configuration templates\n",
    "- log: Related to logs or error/debug info\n",
    "\n",
    "Query: \"{query}\"\n",
    "Category:\"\"\")\n",
    "    category = router_llm.invoke(prompt.format(query=query)).content.strip().lower()\n",
    "    if \"ciq\" in category:\n",
    "        return db_ciq\n",
    "    elif \"template\" in category:\n",
    "        return db_template\n",
    "    elif \"log\" in category:\n",
    "        return db_log\n",
    "    else:\n",
    "        return db_template  # fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "296508ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‡ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 6a0746a1ec1a... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– 4.7 GB                         \n",
      "pulling 4fa551d4f938... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  12 KB                         \n",
      "pulling 8ab4849b038c... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  254 B                         \n",
      "pulling 577073ffcc6c... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  110 B                         \n",
      "pulling 3f8eb4da87fa... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  485 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451d6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Selected source: log\n",
      "\n",
      "ðŸ§  Response:\n",
      " 2025-05-11 12:05:00 [INFO] Base station configured with parameters y1=40, y2=50.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Run the system ===\n",
    "query = \"give me jio_template\"\n",
    "selected_db = route_db(query)\n",
    "\n",
    "# Retrieve docs from selected vector DB\n",
    "results = selected_db.similarity_search(query, k=1)\n",
    "context = results[0].page_content if results else \"No relevant context found.\"\n",
    "\n",
    "# === Final Prompt ===\n",
    "final_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an intelligent assistant. Use the context to answer the query.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Query: {query}\n",
    "\n",
    "Answer:\"\"\")\n",
    "llm = Ollama(model=\"llama3.1:8b\")\n",
    "response = llm.invoke(final_prompt.format(context=context, query=query))\n",
    "\n",
    "# === Output ===\n",
    "print(\"\\nâœ… Selected source:\", results[0].metadata[\"type\"] if results else \"None\")\n",
    "print(\"\\nðŸ§  Response:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dea9aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                  ID              SIZE      MODIFIED     \n",
      "llama3.1:8b           46e0c10c039e    4.9 GB    5 months ago    \n",
      "qwen2.5-coder:1.5b    6d3abb8d2d53    986 MB    5 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbb892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in c:\\programdata\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.59-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.31.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.24 (from langchain-community)\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\saip9\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.6.7)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core) (2.8.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\saip9\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\saip9\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.24->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\saip9\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 20.6 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.59-py3-none-any.whl (437 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Installing collected packages: typing_extensions, sympy, safetensors, httpx-sse, typing-inspection, torch, huggingface-hub, tokenizers, transformers, pydantic-settings, langsmith, sentence-transformers, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "Successfully installed httpx-sse-0.4.0 huggingface-hub-0.31.1 langchain-0.3.25 langchain-community-0.3.23 langchain-core-0.3.59 langchain-text-splitters-0.3.8 langsmith-0.3.42 pydantic-settings-2.9.1 safetensors-0.5.3 sentence-transformers-4.1.0 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 transformers-4.51.3 typing-inspection-0.4.0 typing_extensions-4.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\saip9\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\saip9\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\saip9\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\saip9\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas openpyxl sentence-transformers transformers langchain-community langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a313af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
